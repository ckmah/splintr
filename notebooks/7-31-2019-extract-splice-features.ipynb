{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract splice event features\n",
    "Given a set of RMATS junction count files, aggregate and remove duplicate events. Write these aggregated events to file.\n",
    "\n",
    "**Runtime**: < 5 minutes (I/O limited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 41.2 ms\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from splintr import splice\n",
    "from splintr.splice import SpliceData\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from shutil import copyfile\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.33 ms\n"
     ]
    }
   ],
   "source": [
    "def remove_duplicate_events(df):\n",
    "    duplicated = df.iloc[:, 5:-14].duplicated()\n",
    "    df = df.loc[~duplicated]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ea6cb0e3c146c082222c20dd945854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2202), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "rmats_dir = '../data/encore_rmats'\n",
    "output_dir = '../data/features'\n",
    "\n",
    "events = ['A3SS', 'A5SS', 'MXE', 'RI', 'SE']\n",
    "\n",
    "raw_dir = '../data/encore_raw'\n",
    "\n",
    "# move files over to features\n",
    "for experiment in tqdm(os.listdir(raw_dir)):\n",
    "    experiment_tags = experiment.split('-')\n",
    "    if experiment_tags[-1] == 'HepG2' or experiment_tags[-1] == 'K562':\n",
    "        rbp_name = experiment_tags[0]\n",
    "        cell_line = experiment_tags[-1]\n",
    "        for event in events:\n",
    "            orig_file = f'{raw_dir}/{experiment}/MATS_Norm_output/{event}.MATS.JunctionCountOnly.txt'\n",
    "            copy_file = f'{rmats_dir}/{cell_line}/{event}/{rbp_name}.MATS.JunctionCountOnly.txt'\n",
    "            copyfile(orig_file, copy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b65930ba6549f5919c1a1be9368556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4min 26s\n"
     ]
    }
   ],
   "source": [
    "# Iterate over event -> cell line -> RBP\n",
    "def generate_features(event):\n",
    "    cell_lines = os.listdir(f'{rmats_dir}')\n",
    "    \n",
    "    # cell line\n",
    "    event_all_cell_dataset = []\n",
    "    for cell_line in tqdm(cell_lines, position=1, desc='Cell lines', leave=False):\n",
    "        jc_files = os.listdir(f'{rmats_dir}/{cell_line}/{event}')\n",
    "        \n",
    "        # sample\n",
    "        cell_datasets = []\n",
    "        for jc_file in tqdm(jc_files, position=2, desc='Samples', leave=False):\n",
    "            jc_filepath = f'{rmats_dir}/{cell_line}/{event}/{jc_file}'\n",
    "            sample_name = jc_file.split('.')[0] # parse sample name\n",
    "            \n",
    "            # Load junction counts data\n",
    "            jc = pd.read_csv(jc_filepath, sep='\\t')\n",
    "            jc['event'] = event\n",
    "            \n",
    "            # Set aside non-alternatively spliced events as control\n",
    "            bg_jc = jc.loc[jc['FDR'] > 0.1]\n",
    "            bg_jc = bg_jc.iloc[np.random.randint(bg_jc.shape[0], size=1)]\n",
    "            bg_jc['sample'] = 'bg'\n",
    "            \n",
    "            # Alternatively spliced events\n",
    "            jc = jc.loc[jc['FDR'] < 0.1]\n",
    "            jc['sample'] = sample_name\n",
    "            jc = pd.concat([bg_jc, jc])\n",
    "            \n",
    "            cell_datasets.append(jc)\n",
    "            \n",
    "        # Combine all events for event type\n",
    "        cell_datasets = pd.concat(cell_datasets, ignore_index=True)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        cell_datasets = remove_duplicate_events(cell_datasets)\n",
    "        event_all_cell_dataset.append(cell_datasets)\n",
    "        \n",
    "        # Write to file\n",
    "        file_prefix = f'{output_dir}/{cell_line}_{event}'\n",
    "        cell_datasets.to_csv(f'{file_prefix}.txt', sep='\\t', index=False)\n",
    "\n",
    "    # Combine all events for given event type across all cell lines\n",
    "    event_all_cell_dataset = pd.concat(event_all_cell_dataset, ignore_index=True)\n",
    "    \n",
    "    # remove duplicates\n",
    "    event_all_cell_dataset = remove_duplicate_events(event_all_cell_dataset)\n",
    "    event_all_cell_dataset.to_csv(f'{output_dir}/{event}.txt', sep='\\t', index=False)\n",
    "    \n",
    "p = Pool(4)\n",
    "list(tqdm(p.imap_unordered(generate_features, events), total=len(events)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
