{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pybedtools import BedTool\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "import sys\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = os.listdir('../data/norm_splice/')\n",
    "\n",
    "raw_dir = '../data/encore_events'\n",
    "\n",
    "for d in os.listdir(raw_dir):\n",
    "    if d.endswith('HepG2'):\n",
    "        rbp_name = d.split('-')[0]\n",
    "        \n",
    "        for event in events:\n",
    "            orig_file = f'{raw_dir}/{d}/MATS_Norm_output/{event}.MATS.JunctionCountOnly.txt'\n",
    "            copy_file = f'../data/norm_splice/{event}/{rbp_name}.MATS.JunctionCountOnly.txt'\n",
    "            copyfile(orig_file, copy_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "\n",
    "`?*4 nt` sequence of exon-exon junction windows.\n",
    "\n",
    "`? nt` windows flanking the relevant exon/intron boundaries, extending a maximum of `? nt` into each exon and `? nt` into each intron.\n",
    "\n",
    "Feature windows:\n",
    "- upstream exon window\n",
    "- cassette exon 5' window\n",
    "- cassette exon 3' window\n",
    "- downstream exon window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(rmats_filepath, output_dir):\n",
    "    '''\n",
    "    Generates features as bed files describing genomic regions spanning splice event junctions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rmats_filepath (str) : full path to RMATS junction count file\n",
    "    output_dir (str) : \n",
    "    '''\n",
    "    # Load junction counts data\n",
    "    data = pd.read_csv(rmats_filepath, sep='\\t')\n",
    "    \n",
    "    # Set aside non-alternatively spliced events as control\n",
    "    bg_data = data.loc[data['FDR'] > 0.3]\n",
    "    bg_data = bg_data.iloc[np.random.randint(bg_data.shape[0], size=1)]\n",
    "    \n",
    "    # Alternatively spliced events\n",
    "    data = data.loc[(data['FDR'] < 0.1) & (data['IncLevelDifference'] < 0)]\n",
    "    data = pd.concat([bg_data, data])\n",
    "    \n",
    "    rbp_name = rmats_filepath.split('.')[0]\n",
    "    exon_overlap = 50 # bp into exon to include\n",
    "    intron_overlap = 350 # bp into intron to include\n",
    "\n",
    "    # Write each interval type into own file\n",
    "    upstream_file = open(f'{output_dir}/{rbp_name}.upstream.bed', 'w')\n",
    "    cassette_5p_file = open(f'{output_dir}/{rbp_name}.cassette_5p.bed', 'w')\n",
    "    cassette_3p_file = open(f'{output_dir}/{rbp_name}.cassette_3p.bed', 'w')\n",
    "    downstream_file = open(f'{output_dir}/{rbp_name}.downstream.bed', 'w')\n",
    "    \n",
    "    for i, row in data.iterrows():\n",
    "        # upstream exon 3' region\n",
    "        upstream_3p_start = max(row['upstreamES'], row['upstreamEE'] - exon_overlap)\n",
    "        upstream_3p_end = min(row['exonStart_0base'], row['upstreamEE'] + intron_overlap)\n",
    "        upstream = [upstream_3p_start, upstream_3p_end]\n",
    "\n",
    "        # cassette exon 5' region\n",
    "        cassette_5p_start = max(row['upstreamEE'], row['exonStart_0base'] - intron_overlap)\n",
    "        cassette_5p_end = min(row['exonStart_0base'] + exon_overlap, row['exonEnd'])\n",
    "        cassette_5p = [cassette_5p_start, cassette_5p_end]\n",
    "\n",
    "        # cassette exon 3' region\n",
    "        cassette_3p_start = max(row['exonEnd'] - exon_overlap, row['exonStart_0base'])\n",
    "        cassette_3p_end = min(row['downstreamES'], row['exonEnd'] + intron_overlap)\n",
    "        cassette_3p = [cassette_3p_start, cassette_3p_end]\n",
    "\n",
    "        # downstream exon 5' window\n",
    "        downstream_5p_start = max(row['exonEnd'], row['downstreamES'] - intron_overlap)\n",
    "        downstream_5p_end = min(row['downstreamES'] + exon_overlap, row['downstreamEE'])\n",
    "        downstream = [downstream_5p_start, downstream_5p_end]\n",
    "\n",
    "        # Make sure windows are defined 5' -> 3'\n",
    "        assert (upstream[0] < upstream[1]) \n",
    "        assert (cassette_5p[0] < cassette_5p[1]) \n",
    "        assert (cassette_3p[0] < cassette_3p[1]) \n",
    "        assert (downstream[0] < downstream[1]) \n",
    "\n",
    "        chr = row['chr']\n",
    "\n",
    "        # write bed sequences\n",
    "        upstream_file.write(f'{chr}\\t{upstream[0]}\\t{upstream[1]}\\t{row[\"FDR\"]}\\n')\n",
    "        cassette_5p_file.write(f'{chr}\\t{cassette_5p[0]}\\t{cassette_5p[1]}\\t{row[\"FDR\"]}\\n')\n",
    "        cassette_3p_file.write(f'{chr}\\t{cassette_3p[0]}\\t{cassette_3p[1]}\\t{row[\"FDR\"]}\\n')\n",
    "        downstream_file.write(f'{chr}\\t{downstream[0]}\\t{downstream[1]}\\t{row[\"FDR\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'se_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7bb049b06f0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjc_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnum_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mse_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0moutput_dirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'se_files' is not defined"
     ]
    }
   ],
   "source": [
    "jc_dir = '../data/norm_splice/SE'\n",
    "output_dir = '../data/features/SE'\n",
    "\n",
    "jc_files = [os.path.join(jc_dir, p) for p in os.listdir(jc_dir)]\n",
    "num_files = len(jc_files)\n",
    "output_dirs = [output_dir] * num_files\n",
    "\n",
    "p = Pool(8)\n",
    "for _ in tqdm_notebook(p.imap_unordered(generate_features, jc_files, output_dir), total=num_files):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregate into 1 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde3ea7cc5a24ebb8b42407d855c2bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=893), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_dir = '../data/features/SE'\n",
    "output_suffix = ['upstream.bed', 'cassette_5p.bed', 'cassette_3p.bed', 'downstream.bed']\n",
    "\n",
    "for out_suffix in output_suffix:\n",
    "    out_feature_file = f'{feature_dir}_{out_suffix}'\n",
    "    if os.path.exists(out_feature_file):\n",
    "        os.remove(out_feature_file)\n",
    "    \n",
    "for file in tqdm_notebook(sorted(os.listdir(feature_dir))):\n",
    "    if file == '.ipynb_checkpoints':\n",
    "        continue\n",
    "        \n",
    "    filepath = os.path.join(feature_dir, file)\n",
    "    if os.path.getsize(filepath) > 1:\n",
    "        data = pd.read_csv(filepath, sep='\\t', header=None)\n",
    "\n",
    "        for out_suffix in output_suffix:\n",
    "            if filepath.endswith(out_suffix):\n",
    "                data[4] = file.split('.')[0]\n",
    "                \n",
    "#                 if file.split('.')[0] in keep:\n",
    "                \n",
    "                data.loc[data.iloc[:, 3] > 0.1, 4] = 'negative'\n",
    "                data = data.drop(axis=1, columns=3)\n",
    "                data.to_csv(f'{feature_dir}_{out_suffix}', sep='\\t', header=False, index=False, mode='a')        \n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in all features as single matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for out_suffix in output_suffix:\n",
    "    if out_suffix == 'downstream.bed':\n",
    "        a.append(pd.read_csv('_'.join([feature_dir, out_suffix]), sep='\\t', header=None))\n",
    "    else:\n",
    "        a.append(pd.read_csv('_'.join([feature_dir, out_suffix]), sep='\\t', header=None).iloc[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7187, 13)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = pd.concat(a, axis=1)\n",
    "events.columns = list(range(events.shape[1]))\n",
    "events.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = events.drop_duplicates(subset=events.columns[:-1], keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset events to most common classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "U2AF2       221\n",
       "negative    209\n",
       "U2AF1       173\n",
       "PABPC1       88\n",
       "HNRNPC       79\n",
       "SNRNP70      77\n",
       "MAGOH        72\n",
       "SRFBP1       64\n",
       "PUF60        58\n",
       "SRSF1        54\n",
       "SF3A3        53\n",
       "SRSF3        44\n",
       "RRP9         43\n",
       "EWSR1        42\n",
       "DDX19B       34\n",
       "RPL23A       34\n",
       "SF3B1        26\n",
       "KHSRP        25\n",
       "RAVER1       23\n",
       "HNRNPU       21\n",
       "UCHL5        20\n",
       "EIF4A3       19\n",
       "UBE2L3       17\n",
       "SRSF9        16\n",
       "SF3B4        15\n",
       "PRPF6        14\n",
       "EIF4G1       14\n",
       "HNRNPL       13\n",
       "RBM34        13\n",
       "FTO          13\n",
       "           ... \n",
       "TBRG4         1\n",
       "G3BP2         1\n",
       "RBM47         1\n",
       "ACO1          1\n",
       "PSIP1         1\n",
       "DNAJC2        1\n",
       "PCBP1         1\n",
       "CUGBP1        1\n",
       "NIP7          1\n",
       "AUH           1\n",
       "HNRNPA1       1\n",
       "TFIP11        1\n",
       "PPIG          1\n",
       "G3BP1         1\n",
       "RPS19         1\n",
       "RCC2          1\n",
       "CCAR1         1\n",
       "GRWD1         1\n",
       "ABCF1         1\n",
       "HNRNPUL1      1\n",
       "RBM27         1\n",
       "TARDBP        1\n",
       "XRN2          1\n",
       "PA2G4         1\n",
       "PKM2          1\n",
       "MATR3         1\n",
       "SUGP2         1\n",
       "RBFOX2        1\n",
       "PUS1          1\n",
       "PRPF4         1\n",
       "Name: 12, Length: 172, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[12].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "U2AF2       221\n",
       "negative    209\n",
       "U2AF1       173\n",
       "PABPC1       88\n",
       "HNRNPC       79\n",
       "SNRNP70      77\n",
       "MAGOH        72\n",
       "SRFBP1       64\n",
       "PUF60        58\n",
       "SRSF1        54\n",
       "SF3A3        53\n",
       "SRSF3        44\n",
       "RRP9         43\n",
       "EWSR1        42\n",
       "DDX19B       34\n",
       "RPL23A       34\n",
       "SF3B1        26\n",
       "KHSRP        25\n",
       "RAVER1       23\n",
       "HNRNPU       21\n",
       "UCHL5        20\n",
       "EIF4A3       19\n",
       "UBE2L3       17\n",
       "SRSF9        16\n",
       "SF3B4        15\n",
       "Name: 12, dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep = events[12].value_counts()[:25].index\n",
    "# keep = keep.drop('negative') # remove negative controls\n",
    "events = events.loc[events[12].isin(keep)]\n",
    "events[12].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.shape[0] - (221 + 209+173)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write de-duped events to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [[0,1,2], [3,4,5], [6,7,8], [9,10,11]]\n",
    "feature_cols = [cols + [-1] for cols in feature_cols]\n",
    "\n",
    "for out_suffix, cols in zip(output_suffix, feature_cols):\n",
    "    out_feature_file = f'{feature_dir}_25class_dedup_{out_suffix}'\n",
    "\n",
    "    if os.path.exists(out_feature_file):\n",
    "        os.remove(out_feature_file)\n",
    "\n",
    "    events.iloc[:, cols].to_csv(out_feature_file, sep='\\t', header=False, index=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
