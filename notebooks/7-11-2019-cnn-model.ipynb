{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "import splintr as sp\n",
    "from splintr.splice import rmats_subset_top_events\n",
    "sp.verbose = True\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "from ax import optimize\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "seed = 99\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.set_num_threads=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and transform dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 93.6 ms\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "data_dir = '../data/features'\n",
    "feature_file = f'{data_dir}/SE.txt'\n",
    "feature_df = rmats_subset_top_events(feature_file, 5)\n",
    "feature_df = feature_df.loc[feature_df.IncLevelDifference > 0] # upregulated AS events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.7 ms\n"
     ]
    }
   ],
   "source": [
    "# Randomize sample order\n",
    "rand_sample_i = np.random.choice(feature_df.shape[0], size=feature_df.shape[0], replace=False)\n",
    "\n",
    "# Determine dataset split size\n",
    "train_size, valid_size, test_size = [int(len(rand_sample_i) * s) for s in [0.8, 0.1, 0.1]]\n",
    "train_size += 1\n",
    "\n",
    "# Split into training, validation, and test\n",
    "train_df = feature_df.iloc[rand_sample_i[:train_size]]\n",
    "valid_df = feature_df.iloc[rand_sample_i[train_size : train_size + valid_size]]\n",
    "test_df = feature_df.iloc[rand_sample_i[train_size + valid_size : train_size + valid_size + test_size]]\n",
    "datasets_df = [train_df, valid_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae835ac726148b584ce87014daf6285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c93682c54a4717837bf4963142dd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb1f3ded28fe4fee88192a0495ff6b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "time: 8.79 s\n"
     ]
    }
   ],
   "source": [
    "# Additional parameters for loading data\n",
    "seq_length = 250\n",
    "genome_fa = '../data/hg19.fa'\n",
    "k = 10\n",
    "\n",
    "# Sample from each splice event k times\n",
    "all_data = []\n",
    "for df in datasets_df:\n",
    "    augmented_data = []\n",
    "    for i in tqdm(range(k), total=k):\n",
    "        # Pad and crop transform\n",
    "        tf1 = [sp.PadSequence(seq_length), sp.CropSequence(seq_length)]\n",
    "        augmented_data.append(sp.SpliceEventDataset(feature_file=df,\n",
    "                                                    genome_fa=genome_fa,\n",
    "                                                    transform=tf1))\n",
    "        \n",
    "        # Pad and crop transform on reverse complement\n",
    "        tf2 = [sp.PadSequence(seq_length), sp.CropSequence(seq_length), sp.ReverseComplement()]\n",
    "        augmented_data.append(sp.SpliceEventDataset(feature_file=df,\n",
    "                                                    genome_fa=genome_fa,\n",
    "                                                    transform=tf2))\n",
    "    augmented_data = torch.utils.data.ConcatDataset(augmented_data)\n",
    "    all_data.append(augmented_data)\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AQR       234\n",
      "HNRNPC    219\n",
      "bg        175\n",
      "U2AF2     135\n",
      "RBM15      83\n",
      "U2AF1      55\n",
      "Name: sample, dtype: int64\n",
      "Classes: 6\n",
      "time: 6.67 s\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical labels to numerical\n",
    "print(feature_df['sample'].value_counts())\n",
    "label_names = pd.factorize(feature_df['sample'])\n",
    "\n",
    "num_classes = int(max(label_names[0]) + 1)\n",
    "print(f'Classes: {num_classes}')\n",
    "\n",
    "# Balance class sampling using weighted sampler\n",
    "samplers = []\n",
    "for dataset in all_data:\n",
    "    labels = [sample[1] for sample in dataset] # get label of each sample\n",
    "    weights = 100. / pd.Series(labels).value_counts() # class weights\n",
    "    weights = weights[labels].values \n",
    "    sampler = WeightedRandomSampler(weights=weights, num_samples=len(weights))\n",
    "    samplers.append(sampler)\n",
    "\n",
    "train_sampler, valid_sampler, test_sampler = samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.41 ms\n"
     ]
    }
   ],
   "source": [
    "sp.learning._calc_conv_pad(250, 50, 40, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>run_duration</th>\n",
       "      <th>num_classes</th>\n",
       "      <th>c1_in</th>\n",
       "      <th>...</th>\n",
       "      <th>c1_stride_w</th>\n",
       "      <th>c2_out</th>\n",
       "      <th>c2_kernel_w</th>\n",
       "      <th>c2_filter</th>\n",
       "      <th>c2_stride_w</th>\n",
       "      <th>fc_out</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.793340</td>\n",
       "      <td>1.816674</td>\n",
       "      <td>0.171845</td>\n",
       "      <td>0.161111</td>\n",
       "      <td>6.987569</td>\n",
       "      <td>7.193526</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.793093</td>\n",
       "      <td>1.818034</td>\n",
       "      <td>0.169348</td>\n",
       "      <td>0.149444</td>\n",
       "      <td>6.848788</td>\n",
       "      <td>14.120342</td>\n",
       "      <td>6</td>\n",
       "      <td>250</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch  train_loss  valid_loss  train_accuracy  valid_accuracy  \\\n",
       "0    1      1    1.793340    1.816674        0.171845        0.161111   \n",
       "1    1      2    1.793093    1.818034        0.169348        0.149444   \n",
       "\n",
       "   epoch_duration  run_duration  num_classes  c1_in  ...  c1_stride_w  c2_out  \\\n",
       "0        6.987569      7.193526            6    250  ...            5       6   \n",
       "1        6.848788     14.120342            6    250  ...            5       6   \n",
       "\n",
       "   c2_kernel_w  c2_filter  c2_stride_w  fc_out  batch_size      lr  \\\n",
       "0            4          8            4       8          32  0.0001   \n",
       "1            4          8            4       8          32  0.0001   \n",
       "\n",
       "   weight_decay  dropout  \n",
       "0             0      0.1  \n",
       "1             0      0.1  \n",
       "\n",
       "[2 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-fe17c1cea32d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# zero gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# calculate gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_train_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.2 s\n"
     ]
    }
   ],
   "source": [
    "# Run(num_classes=6, c1_in=250, c1_out=50, c1_kernel_w=10, c1_filter=64, c1_stride_w=5, c2_out=6, c2_kernel_w=4, c2_filter=8, c2_stride_w=4, fc_out=8, batch_size=128, lr=0.01, weight_decay=0, dropout=0)\n",
    "params = OrderedDict(\n",
    "    # model parameters\n",
    "    num_classes = [num_classes],\n",
    "    c1_in = [seq_length],\n",
    "    c1_out = [50],\n",
    "    c1_kernel_w = [20],\n",
    "    c1_filter = [64],\n",
    "    c1_stride_w = [5],\n",
    "    c2_out = [6],\n",
    "    c2_kernel_w = [4],\n",
    "    c2_filter = [8],\n",
    "    c2_stride_w = [4],\n",
    "    fc_out = [8],\n",
    "    \n",
    "    # hyperparameters\n",
    "    batch_size = [32],\n",
    "    lr = [0.0001],\n",
    "    weight_decay = [0],\n",
    "    dropout = [0]\n",
    ")\n",
    "\n",
    "manager = sp.RunManager()\n",
    "is_first_run = True\n",
    "for run in sp.RunBuilder.get_runs(params):    \n",
    "    # Initialize model and dataset\n",
    "    network = sp.SplintrNet(num_classes=run.num_classes,\n",
    "                      c1_in=run.c1_in,\n",
    "                      c1_out=run.c1_out,\n",
    "                      c1_kernel_w=run.c1_kernel_w,\n",
    "                      c1_filter=run.c1_filter,\n",
    "                      c1_stride_w=run.c1_stride_w,\n",
    "                      c2_out=run.c2_out,\n",
    "                      c2_kernel_w=run.c2_kernel_w,\n",
    "                      c2_filter=run.c2_filter,\n",
    "                      c2_stride_w=run.c2_stride_w,\n",
    "                      dropout=run.dropout,\n",
    "                      fc_out=run.fc_out).cuda(device)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=run.batch_size, sampler=train_sampler)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=run.batch_size, sampler=valid_sampler)\n",
    "\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=run.lr, weight_decay=run.weight_decay)\n",
    "    log_dir = '/home/ubuntu/tb/8-05-19-6class/'\n",
    "    # Display brief summary of first model\n",
    "    if is_first_run:\n",
    "        is_first_run = False\n",
    "        summary(network.cuda(), input_size=(4, 4, seq_length), device='cuda')\n",
    "#         util.show_sample(train_dataset[np.random.randint(len(train_dataset))], class_names=label_names)\n",
    "    \n",
    "    # Perform training\n",
    "    manager.begin_run(run, network, train_loader, valid_loader, log_dir)\n",
    "    network.cuda()\n",
    "    for epoch in range(30):\n",
    "        \n",
    "        manager.begin_epoch()\n",
    "        \n",
    "        # Train on batch\n",
    "        for batch in train_loader:\n",
    "            seqs, labels = batch\n",
    "            preds = network(seqs.cuda(device)) # pass batch\n",
    "            loss = F.cross_entropy(preds, labels.cuda(device)) # calculate loss\n",
    "            optimizer.zero_grad() # zero gradients\n",
    "            loss.backward() # calculate gradients\n",
    "            optimizer.step() # update weights\n",
    "\n",
    "            manager.track_train_loss(loss)\n",
    "            manager.track_train_num_correct(preds, labels.cuda(device))\n",
    "        \n",
    "        # Check validation set\n",
    "        with torch.no_grad():\n",
    "            for data in valid_loader:\n",
    "                seqs, labels = data\n",
    "                preds = network(seqs.cuda(device))\n",
    "                loss = F.cross_entropy(preds, labels.cuda(device))\n",
    "                \n",
    "                manager.track_valid_loss(loss)\n",
    "                manager.track_valid_num_correct(preds, labels.cuda(device))\n",
    "\n",
    "        manager.end_epoch()\n",
    "    manager.end_run(train_class_names=label_names[1],\n",
    "                    valid_class_names=label_names[1])\n",
    "manager.save('../results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
